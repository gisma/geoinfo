---
title: "Part 1: Analyzing massive Sentinel Data amounts with R, gdalcubes, and STAC"
author:
- Marius Appel
- adapted by Chris Reudenbach
date: "Sept. 1, 2021"
link-citations: yes
output: 
  html_document:
    toc: true
    toc_float:  
      collapsed: false
      smooth_scroll: false
    toc_depth: 2
    theme: flatly
editor_options: 
  chunk_output_type: console
---

```{r setup , include = FALSE}

tutorialDir = paste0(usethis::proj_get(), "/data/tutorial/")
figtrim <- function(path) {
  img <- magick::image_trim(magick::image_read(path))
  magick::image_write(img, path)
  path
}
knitr::opts_chunk$set(echo = TRUE)
#knitr::opts_chunk$set(eval = FALSE)
knitr::opts_chunk$set(out.width = "100%")
knitr::opts_chunk$set(cache = TRUE)
knitr::opts_chunk$set(dev = "png")
knitr::opts_chunk$set(fig.process = figtrim)
knitr::opts_chunk$set(fig.width = 15, fig.height = 7.5)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(root.dir = tutorialDir)
knitr::opts_chunk$set(fig.path=paste0(tutorialDir,'figs/'))
```


# Introduction

This tutorial demonstrates how we can access and process Sentinel-2 data in the cloud using the R packages [`rstac`](https://cran.r-project.org/package=rstac) [@rstac] and [`gdalcubes`](https://cran.r-project.org/package=gdalcubes) [@gdalcubes].

Two examples on the creation of composite images and more complex time series analysis will introduce important functions of both packages.

Other packages used in this tutorial include [`stars`](https://cran.r-project.org/package=stars)[@stars] and [`tmap`](https://cran.r-project.org/package=tmap)[@tmap] for creating interactive maps, [`sf`](https://cran.r-project.org/package=sf)[@sf] for processing vector data, and [`colorspace`](https://cran.r-project.org/package=colorspace)[@colorspace] for visualizations with accessible colors.

# Retrieve some interesting reference geometries

```{r hessen}
library(sf)
library(rnaturalearth)
library(tidyverse)
library(downloader)
library(tmap)
library(gdalcubes)
country <- ne_states(country = 'germany',returnclass='sf')
hessen= country %>% filter(name == "Hessen")

# ----  Official geometry data of the municipal areas  (Bundesamt für Geodäsie und Kartographie)
# https://gdz.bkg.bund.de/index.php/default/open-data/verwaltungsgebiete-1-250-000-mit-einwohnerzahlen-ebenen-stand-31-12-vg250-ew-ebenen-31-12.html
if (!file.exists(paste0(tutorialDir,"municipial.zip"))){
  downloader::download(url ="https://daten.gdz.bkg.bund.de/produkte/vg/vg250-ew_ebenen_1231/aktuell/vg250-ew_12-31.tm32.shape.ebenen.zip", destfile = paste0(tutorialDir,"municipial.zip"))
  # Entpackt werden nur die Gemeindegeometrien
  unzip(zipfile = paste0(tutorialDir,"municipial.zip"),
        files = c("vg250-ew_12-31.tm32.shape.ebenen/vg250-ew_ebenen_1231/VG250_GEM.shp",
                  "vg250-ew_12-31.tm32.shape.ebenen/vg250-ew_ebenen_1231/VG250_GEM.dbf",
                  "vg250-ew_12-31.tm32.shape.ebenen/vg250-ew_ebenen_1231/VG250_GEM.shx",
                  "vg250-ew_12-31.tm32.shape.ebenen/vg250-ew_ebenen_1231/VG250_GEM.prj"),
        exdir = paste0(tutorialDir,"municipial/"),
        junkpaths = TRUE)
}
municipal_sf = st_read(paste0(tutorialDir,"municipial/VG250_GEM.shp"))

```

We aim at generating a cloud-free composite image of our study area for June, 2018 and we use the `rstac` package to find suitable Sentinel-2 images. However, to use the `bbox` argument of the corresponding function `stac_search()` for spatial filtering, we first need to derive and transform the bounding box to latitude / longitude (WGS84) values, for which we use the `st_bbox()` and `st_transform()` functions. In addition we adapt the projection of the referencing vector objects.

```{r geometries}
hessen_3035 = st_transform(hessen,crs = 3035)
hessen_32632 = st_transform(hessen,crs = 32632)
bbox = st_bbox(hessen) 
st_as_sfc(bbox) |>
  st_transform("EPSG:4326") |>
  st_bbox() -> bbox_wgs84

# Projektion der Geometriedaten von ETRS89 / UTM zone 32N (N-E) 3044 in ETRS89-extended / LAEA Europe 3035
municipal_3035 = st_transform(municipal_sf, 3035)
lahntal_3035 = municipal_3035 %>% filter(GEN == "Lahntal")
lahntal_4326 = st_transform(lahntal_3035,crs = 4326)
lahntal_32632 = st_transform(lahntal_3035,crs = 32632)
tmap_mode("view")
tm_shape(st_as_sfc(bbox)) + tm_polygons()  + tm_shape(lahntal_3035) +   tm_polygons()
```


# Creating composite images and handling gdalcubes

Our study area (the main land area of the Netherlands) is given in a (poorly) digitized GeoPackage file `NL.gpkg`. We can create a simple interactive map using the `sf` and `tmap` packages by running:


## Querying images with `rstac`

Now, we can specify our STAC-API endpoint, and post a STAC search request using the transformed bounding box, the datetime range, and the collection name "sentinel-s2-l2a-cogs".

```{r rstac1}
library(rstac)
s = stac("https://earth-search.aws.element84.com/v0")
items = s |>
  stac_search(collections = "sentinel-s2-l2a-cogs",
              bbox = c(bbox_wgs84["xmin"],bbox_wgs84["ymin"],
                       bbox_wgs84["xmax"],bbox_wgs84["ymax"]), 
              datetime = "2021-06-01/2021-07-30",
              limit = 500) |>
  post_request() 
items
```

By default, the result of the used SPAC API contains only up to 10 items and we need to increase this value using the `limit` argument. Here, we got a list of 260 STAC items.

Looking at one of the items, we see:

```{r}
names(items$features[[10]])
```

The `assets` element contains direct links to the image files for separate bands and the properties element contains a lot of useful metadata including cloud coverage, datetime, projection, and more:

```{r}
items$features[[10]]$assets$B05
items$features[[10]]$properties$`eo:cloud_cover`
```

## Creating an image collection

Next, we load the `gdalcubes` package and use this list of features from `rstac` to create a gdalcubes image collection object with the `stac_image_collection()` function. Compared to using gdalcubes with imagery on local storage, this does not need to open and read metadata from all files because STAC items already contain all relevant metadata including datetime, spatial extent, and how files relate to bands. As a result, creation of an image collection from STAC is quite fast.

```{r}
library(gdalcubes)
s2_collection = stac_image_collection(items$features)
s2_collection
```

However, this function takes some further useful arguments. First, we see that our image collection does not contain the `SCL` band that contains information on cloud and cloud shadow pixels. This band is ignored by default, because it is missing the `eo:bands` properties in the STAC API response. As an alternative to consider this band, we can specify asset names manually using the `asset_names` argument. Second, the result contains all images although there are some with almost no clear pixels. To reduce the number of images, we can provide a function as the `property_filter` argument. In this case the cloud cover is set to a value of maximum 20%. This function receives the properties element (a list) of a STAC item as argument and is expected to produce a single logical value, where an image is ignored if the function returns FALSE.

```{r}
assets = c("B01","B02","B03","B04","B05","B06", "B07","B08","B8A","B09","B11","SCL")
s2_collection = stac_image_collection(items$features, 
                                      asset_names = assets, 
                                      property_filter = function(x) {x[["eo:cloud_cover"]] < 5})
s2_collection
```

As a result we get an image collection with 32 images and the `SCL` band.

## Defining the data cube geometry

The next step in gdalcubes is to specify the geometry of our target data cube, which is called the *data cube view*. The data cube view is independent from specific image collections and hence does not contain information on spectral bands. In the following code, we use the `cube_view()` function to create and specify a coarse resolution data cube with cell size 200m x 200m x 30 days, using the Lambert equal area projection for Europe:

```{r}
v.hessen.overview = cube_view(srs="EPSG:32632",  
                              dx=200, dy=200, 
                              dt="P30D", 
                              aggregation="median", 
                              resampling = "average",
                              extent=list(t0 = "2021-06-01", 
                                          t1 = "2021-07-30",
                                          left=st_bbox(hessen_32632)["xmin"]-1000,
                                          right=st_bbox(hessen_32632)["xmax"]+1000,
                                          top=st_bbox(hessen_32632)["ymax"] + 1000,
                                          bottom=st_bbox(hessen_32632)["ymin"]-1000)
                              )
v.hessen.overview
```

The messages simply tell us that the extent of the data cube has been enlarged because there can't be anything like partial pixels. Notice that the resampling and aggregation methods define how pixels will be resampled in space and how pixel values from different days within the same data cube cell will be aggregated while aligning images with the target cube geometry. Our data cube geometry has 1595 x 1387 x 1 pixels in space and time directions respectively.

## Creating, processing, and plotting the data cube

Afterwards, we can combine our image collection and cube view and create, process, and plot our actual data cube. To ignore pixels that have been classified as clouds or cloud shadows in individual images, we first need to create a mask object that simply tells gdalcubes that corresponding pixels with values 3,8, or 9 (see [here](https://sentinels.copernicus.eu/web/sentinel/technical-guides/sentinel-2-msi/level-2a/algorithm)) in the SCL band will not contribute to the data cube values and ignored during the temporal aggregation step.

The `raster_cube()` function then takes the image collection, data cube view, and the mask, and creates a virtual data cube. Calling this function does not start any computations or data transfers but simply returns a proxy object, which knows *what to do*. The functions `select_bands()` and `filter_geom()` to subset spectral bands and crop a data cube by a polygon repsectively both take a data cube as an input and produce a proxy object (or virtual data cube) as a result. Calling `plot()` will eventually start all the computations and plot the result. Computations are multithreaded (we use up to 16 threads here) and no intermediate results of the operations are written to disk.

```{r hessen_rgb}
S2.mask = image_mask("SCL", values = c(3,8,9))
gdalcubes_options(threads = 8)
rgb = raster_cube(s2_collection, v.hessen.overview, S2.mask) |>
  select_bands(c("B02", "B03", "B04")) |>
  filter_geom(hessen_32632$geom) |>
  plot(rgb = 3:1, zlim=c(0,1500))
```

If we are interested in a smaller area, at higher resolution, we can create a data cube with a different data cube view as in the following example.

```{r lahntal}
v.lahntal = cube_view(view = v.hessen.overview, 
                      dx=10, 
                      dy=10,
                      extent=list(left=st_bbox(lahntal_32632)["xmin"],
                                  right=st_bbox(lahntal_32632)["xmax"],
                                  top=st_bbox(lahntal_32632)["ymax"],
                                  bottom=st_bbox(lahntal_32632)["ymin"]
                                  )
                      )
 raster_cube(s2_collection, v.lahntal, S2.mask) |>
   select_bands(c("B02", "B03", "B04")) |>
   plot(rgb = 3:1, zlim=c(0,1500))
```

## Operations on data cubes

The gdalcubes package comes with some built-in operations to process data cubes. The following operations produce a derived data cube from one or more input data cubes.

+----------------+----------------------------------------------------------------------------+
| Operator       | Description                                                                |
+================+============================================================================+
| `apply_pixel`  | Apply arithmetic expressions on band values per pixel.                     |
+----------------+----------------------------------------------------------------------------+
| `fill_time`    | Fill missing values by simple time series interpolation.                   |
+----------------+----------------------------------------------------------------------------+
| `filter_pixel` | Filter pixels based on logical expressions.                                |
+----------------+----------------------------------------------------------------------------+
| `filter_geom`  | Filter pixels that do not intersect with a given input geometry            |
+----------------+----------------------------------------------------------------------------+
| `join_bands`   | Combine bands of two or more identically shaped input data cubes.          |
+----------------+----------------------------------------------------------------------------+
| `reduce_space` | Apply a reducer function over time slices of a data cube.                  |
+----------------+----------------------------------------------------------------------------+
| `reduce_time`  | Apply a reducer function over individual pixel time series.                |
+----------------+----------------------------------------------------------------------------+
| `select_bands` | Select a subset of a data cube's bands.                                    |
+----------------+----------------------------------------------------------------------------+
| `window_time`  | Apply a moving window reducer or kernel over individual pixel time series. |
+----------------+----------------------------------------------------------------------------+

There are some more functions for exporting data cubes as netCDF or (cloud-optimized) GeoTIFF files, to read data cubes from netCDF files, to compute summary statistics over polygons (zonal statistics), to query data cube values by irregular spatiotemporal points, and to create animations.

In the example below, we compute the normalized difference vegetation index (NDVI), leave out values with NDVI \<= 0 and plot the example. A custom color palette from the colorspace package is used to use light yellow for lower and green for higher NDVI values.

```{r hessen_ndvi}
library(colorspace)
ndvi.col = function(n) {
  rev(sequential_hcl(n, "Green-Yellow"))
  }
raster_cube(s2_collection, v.hessen.overview, S2.mask) %>%
  select_bands(c("B04", "B08")) %>%
  filter_geom(hessen_32632$geom) %>%
  apply_pixel("(B08-B04)/(B08+B04)", "NDVI") %>%
  filter_pixel("NDVI > 0") %>%
  plot(key.pos = 1, zlim=c(0,1), col = ndvi.col)
```

We can see that some additional water areas with NDVI \< 0 have been set to NA.

## Interactive maps

We can convert data cubes to `stars` objects and use `tmap` for interactive mapping:

```{r hessen_ndvi_tmap}
library(stars)
library(tmap)
raster_cube(s2_collection, v.hessen.overview, S2.mask) |>
  select_bands(c("B04", "B08")) |>
  filter_geom(hessen$geom) |>
  apply_pixel("(B08-B04)/(B08+B04)", "NDVI") |>
  filter_pixel("NDVI > 0") |> 
  st_as_stars() |>
  tm_shape() + tm_raster()
```

# Summary

This example has shown how satellite imagery can be accessed and analyzed `STAC` and `gdalcubes`. The analysis has been rather simple by creating cloud-free composite images for only two months. However, for the chosen example the data originated from more than 30 Sentinel-2 images. Only downloading all the data first would be a nightmare. 

The above approach is straightforward and make it simple to run the analysis in different areas of interest. The checking of transferability of methods and their application may become much easier. The part two of the tutorial will focus on more complex time series processing for a smaller area.

